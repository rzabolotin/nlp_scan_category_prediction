{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Построение ансамбля\n\nНоутбук использует модели натренированные ранее (в других ноутбуках подкюченных к этому)\nСуммирует вероятности предсказанные моделями, и предсказывает класс с наиболшей вероятностью.\n\nУ меня было 2 модели в ансамбле.\nНо предсказание оказалось точно таким же, какое было у моей лучшей модели.\n\nИспользовал код с классом, который написал во время тренировки моделей. Ну и очень удобно получилось вызывать модели\n```\nresult = []\nfor model_path in MODELS_PATH:\n    model = ScanClassifier(\n        model_name=MODEL_NAME, \n        label_encoder=label_encoder,\n        max_len=MAX_LEN\n    )\n    model.load(model_path)\n    result += [model.predict_proba(test)]\n ```","metadata":{}},{"cell_type":"code","source":"!nvidia-smi -L","metadata":{"_uuid":"f638d153-fca3-4d03-a620-6485d02c6069","_cell_guid":"68feb63b-b138-4813-a3d9-17bbdd737bfd","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-19T22:39:32.967169Z","iopub.execute_input":"2022-06-19T22:39:32.967916Z","iopub.status.idle":"2022-06-19T22:39:33.652408Z","shell.execute_reply.started":"2022-06-19T22:39:32.967503Z","shell.execute_reply":"2022-06-19T22:39:33.651421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture dev_null\n!pip install transformers\n!pip install GPUtil","metadata":{"execution":{"iopub.status.busy":"2022-06-19T22:39:33.655557Z","iopub.execute_input":"2022-06-19T22:39:33.655862Z","iopub.status.idle":"2022-06-19T22:39:56.960969Z","shell.execute_reply.started":"2022-06-19T22:39:33.655834Z","shell.execute_reply":"2022-06-19T22:39:56.959928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport functools\n\n# For data manipulation\nimport numpy as np\nimport pandas as pd\nimport warnings\nimport pickle\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder\n\nimport matplotlib.pyplot as plt\nfrom pylab import rcParams\n\nimport torch\nimport torch.nn as nn\n\n# For Transformer Models\nfrom transformers import (\n    AdamW,\n    AutoTokenizer, \n    AutoModelForSequenceClassification, \n    DataCollatorForLanguageModeling, \n    get_scheduler,\n    Trainer, \n    TrainingArguments\n)\n\nfrom tqdm.auto import tqdm\nimport gc\nfrom GPUtil import showUtilization as gpu_usage","metadata":{"execution":{"iopub.status.busy":"2022-06-19T22:39:56.962663Z","iopub.execute_input":"2022-06-19T22:39:56.964178Z","iopub.status.idle":"2022-06-19T22:40:04.574965Z","shell.execute_reply.started":"2022-06-19T22:39:56.964135Z","shell.execute_reply":"2022-06-19T22:40:04.574145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"warnings.filterwarnings('ignore')\n\nrcParams['figure.figsize'] = 10, 5\n\n%config InlineBackend.figure_format = 'svg' \n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-06-19T22:40:04.577237Z","iopub.execute_input":"2022-06-19T22:40:04.577786Z","iopub.status.idle":"2022-06-19T22:40:04.596896Z","shell.execute_reply.started":"2022-06-19T22:40:04.577757Z","shell.execute_reply":"2022-06-19T22:40:04.596066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MODEL_NAME = \"sberbank-ai/sbert_large_nlu_ru\"\n\nDATA_PATH = \"/kaggle/input/scan-classification-challange/\"\nENCODER_PATH = \"../input/scan-training-models-for-ansamble/label_encoder.pkl\"\n\nMODELS_PATH = [\n     \"../input/try-another-model-transformer-sber/sb_model.h5\",\n     \"../input/scan-training-models-for-ansamble/trained-models/model_overall.h5\"\n]\n\nRANDOM_STATE = 42\nBATCH_SIZE = 6\nNUM_WORKERS = 2\nMAX_LEN = 200\nNUM_EPOCHS = 3\nNUM_FOLDS = 3\n\nDEBUG = True\n\ntorch.manual_seed(RANDOM_STATE);\nif DEBUG:\n    os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n","metadata":{"execution":{"iopub.status.busy":"2022-06-19T22:57:55.196587Z","iopub.execute_input":"2022-06-19T22:57:55.197331Z","iopub.status.idle":"2022-06-19T22:57:55.203667Z","shell.execute_reply.started":"2022-06-19T22:57:55.197285Z","shell.execute_reply":"2022-06-19T22:57:55.202659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(ENCODER_PATH, \"rb\") as file_pickle:\n    label_encoder = pickle.load(file_pickle)","metadata":{"execution":{"iopub.status.busy":"2022-06-19T22:40:04.610226Z","iopub.execute_input":"2022-06-19T22:40:04.611435Z","iopub.status.idle":"2022-06-19T22:40:04.622708Z","shell.execute_reply.started":"2022-06-19T22:40:04.611395Z","shell.execute_reply":"2022-06-19T22:40:04.62195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ScanClassifier:\n    def __init__(self, model_name, label_encoder, max_len):\n        self._model_name = model_name\n        self._label_encoder = label_encoder\n        self._tokenizer = AutoTokenizer.from_pretrained(self._model_name)\n        self._model = AutoModelForSequenceClassification.from_pretrained(\n            self._model_name,\n            num_labels=len(self._label_encoder.classes_)\n        )\n        self._data_collator = DataCollatorForLanguageModeling(tokenizer=self._tokenizer);\n        self._max_len = max_len\n        self._is_trained = False\n        \n    def save(self, path):\n        torch.save(self._model.state_dict(), path)\n    \n    def load(self, path):\n        self._model.load_state_dict(torch.load(path))\n    \n    def train(self, train_dataset : pd.DataFrame, valid_dataset : pd.DataFrame, num_epochs=NUM_EPOCHS, batch_size=BATCH_SIZE):\n        train_data_loader = self._prepare_data_loader(train_dataset, batch_size)\n        valid_data_loader = self._prepare_data_loader(valid_dataset, batch_size)\n        \n        num_training_steps = NUM_EPOCHS * len(train_data_loader)\n        \n        optimizer = AdamW(self._model.parameters(), lr=5e-5)\n        \n        lr_scheduler = get_scheduler(\n            \"linear\",\n            optimizer=optimizer,\n            num_warmup_steps=0,\n            num_training_steps=num_training_steps,\n        )\n        \n        device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n        self._model.to(device)\n        \n        progress_bar = tqdm(range(num_training_steps))\n\n        for epoch in range(NUM_EPOCHS):\n            self._model.train()\n            train_loss = 0.0\n            min_valid_loss = np.inf\n            for batch in train_data_loader:\n                batch = {k: v.to(device) for k, v in batch.items()}\n                outputs = self._model(**batch)\n                loss = outputs.loss\n                loss.backward()\n                optimizer.step()\n                lr_scheduler.step()\n                optimizer.zero_grad()\n                progress_bar.update(1)\n                train_loss += loss.detach().item()\n            \n            valid_loss = 0.0\n            self._model.eval()\n            for batch in valid_data_loader:\n                batch = {k: v.to(device) for k, v in batch.items()}\n                outputs = self._model(**batch)\n                valid_loss += outputs.loss.detach().item()\n\n            print(f'Epoch {epoch+1} \\t\\t Training Loss: {train_loss / len(train_data_loader)} \\t\\t Validation Loss: {valid_loss / len(valid_data_loader)}')\n            if min_valid_loss > valid_loss:\n                print(f'Validation Loss Decreased({min_valid_loss:.6f}--->{valid_loss:.6f}) \\t Saving The Model')\n                min_valid_loss = valid_loss\n                # Saving State Dict\n                # torch.save(model.state_dict(), 'saved_model.pth')\n    \n    \n    def predict_proba(self, dataset, batch_size=BATCH_SIZE):\n        self._model.eval()\n        \n        data_loader = self._prepare_data_loader(dataset, batch_size, for_train=False)\n        \n        device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n        self._model.to(device)\n        \n        results = []\n        for i,batch in enumerate(data_loader):\n            batch = {k: v.to(device) for k, v in batch.items()}\n            with torch.no_grad():\n                outputs = self._model(**batch)\n\n            predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n            results.append(predictions)\n        \n        predictions = torch.cat(results,0).cpu().numpy()\n        \n        return(predictions)\n    \n    def predict(self, dataset, batch_size=BATCH_SIZE):\n        pred_proba = self.predict_proba(dataset, batch_size=batch_size)\n        pred_labels = np.argmax(pred_proba,1)\n        pred_class = self._label_encoder.inverse_transform(pred_labels)\n        return(pred_class)\n        \n    def _prepare_data_loader(self, dataset, batch_size, for_train=True):\n        if for_train:\n            labels = self._label_encoder.transform(dataset[\"class\"])\n        else:\n            labels = np.zeros(dataset.shape[0])\n        \n        torch_dataset = Dataset(\n            text=dataset.text.values, \n            target=labels, \n            tokenizer=self._tokenizer, \n            max_len=self._max_len,\n            num_labels=len(self._label_encoder.classes_)\n        )\n\n        data_loader = torch.utils.data.DataLoader(\n            torch_dataset, \n            batch_size=batch_size,\n            shuffle=for_train,\n            num_workers=NUM_WORKERS\n        )\n        \n        return data_loader\n\n        \nclass Dataset:\n    def __init__(self, text, target, tokenizer, max_len, num_labels):\n        self.text = text\n        self.target = target\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n\n    def __len__(self):\n        return len(self.text)\n\n    def __getitem__(self, item):\n        text = str(self.text[item])\n        inputs = self.tokenizer(\n            text, \n            max_length=self.max_len, \n            padding=\"max_length\", \n            truncation=True\n        )\n\n        ids = inputs[\"input_ids\"]\n        mask = inputs[\"attention_mask\"]\n        target = self.target[item]\n\n        return {\n            \"input_ids\": torch.tensor(ids, dtype=torch.long),\n            \"attention_mask\": torch.tensor(mask, dtype=torch.long),\n            \"labels\": torch.tensor(target, dtype=torch.long)\n        }\n        ","metadata":{"execution":{"iopub.status.busy":"2022-06-19T22:40:04.624118Z","iopub.execute_input":"2022-06-19T22:40:04.624713Z","iopub.status.idle":"2022-06-19T22:40:04.651835Z","shell.execute_reply.started":"2022-06-19T22:40:04.624679Z","shell.execute_reply":"2022-06-19T22:40:04.651118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv(DATA_PATH+'df_test.csv',)","metadata":{"execution":{"iopub.status.busy":"2022-06-19T22:40:04.65343Z","iopub.execute_input":"2022-06-19T22:40:04.654117Z","iopub.status.idle":"2022-06-19T22:40:05.026601Z","shell.execute_reply.started":"2022-06-19T22:40:04.654077Z","shell.execute_reply":"2022-06-19T22:40:05.025699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test = test.iloc[:100]","metadata":{"execution":{"iopub.status.busy":"2022-06-19T22:56:52.648622Z","iopub.execute_input":"2022-06-19T22:56:52.649016Z","iopub.status.idle":"2022-06-19T22:56:52.653681Z","shell.execute_reply.started":"2022-06-19T22:56:52.648982Z","shell.execute_reply":"2022-06-19T22:56:52.652799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = []\nfor model_path in MODELS_PATH:\n    model = ScanClassifier(\n        model_name=MODEL_NAME, \n        label_encoder=label_encoder,\n        max_len=MAX_LEN\n    )\n    model.load(model_path)\n    result += [model.predict_proba(test)]","metadata":{"execution":{"iopub.status.busy":"2022-06-19T22:58:01.168925Z","iopub.execute_input":"2022-06-19T22:58:01.16985Z","iopub.status.idle":"2022-06-19T22:58:27.951252Z","shell.execute_reply.started":"2022-06-19T22:58:01.169794Z","shell.execute_reply":"2022-06-19T22:58:27.950165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result","metadata":{"execution":{"iopub.status.busy":"2022-06-19T22:58:27.953125Z","iopub.execute_input":"2022-06-19T22:58:27.953485Z","iopub.status.idle":"2022-06-19T22:58:27.963026Z","shell.execute_reply.started":"2022-06-19T22:58:27.953452Z","shell.execute_reply":"2022-06-19T22:58:27.962291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"overall_proba = functools.reduce(np.add, result)","metadata":{"execution":{"iopub.status.busy":"2022-06-19T22:58:48.668103Z","iopub.execute_input":"2022-06-19T22:58:48.668696Z","iopub.status.idle":"2022-06-19T22:58:48.673163Z","shell.execute_reply.started":"2022-06-19T22:58:48.668657Z","shell.execute_reply":"2022-06-19T22:58:48.672321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_labels = np.argmax(result[0],1)\npred_class = label_encoder.inverse_transform(pred_labels)","metadata":{"execution":{"iopub.status.busy":"2022-06-19T22:58:50.469237Z","iopub.execute_input":"2022-06-19T22:58:50.469794Z","iopub.status.idle":"2022-06-19T22:58:50.47541Z","shell.execute_reply.started":"2022-06-19T22:58:50.469756Z","shell.execute_reply":"2022-06-19T22:58:50.47448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test[\"predictions\"] = pred_class","metadata":{"execution":{"iopub.status.busy":"2022-06-19T22:58:51.037757Z","iopub.execute_input":"2022-06-19T22:58:51.038727Z","iopub.status.idle":"2022-06-19T22:58:51.04483Z","shell.execute_reply.started":"2022-06-19T22:58:51.038692Z","shell.execute_reply":"2022-06-19T22:58:51.044053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test","metadata":{"execution":{"iopub.status.busy":"2022-06-19T22:58:51.45499Z","iopub.execute_input":"2022-06-19T22:58:51.455535Z","iopub.status.idle":"2022-06-19T22:58:51.470823Z","shell.execute_reply.started":"2022-06-19T22:58:51.455499Z","shell.execute_reply":"2022-06-19T22:58:51.469935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({'id':range(pred_class.shape[0]),\n                           'class':pred_class},\n                          columns=['id', 'class'])\nsubmission.to_csv('submission.csv', index=False)\nsubmission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}