# Мое решение задачи SCAN classification challenge

[Ссылка на kaggle](https://www.kaggle.com/competitions/scan-classification-challange)

## Мое решение
В рамках соревнования я сделал модель с помощью библиотеки [hugging face](https://huggingface.co/) и открытой [модели сбербанка](https://huggingface.co/sberbank-ai/sbert_large_nlu_ru), которая позволила предсказать правильный класс новости по ее тексту с точностью **0.92787**

Также в рамках решения, я пробовал различные варианты: 
- Использовать библиотеку fasttext
- Построить ансамбль из разных моделей (натренировать 3 модели на стратифицированных фолдах)
- Написал класс обертку, для упрощения процесса обучения hugging face



## Описание задачи:

SCAN (https://scan-interfax.ru/) - это система Международной информационной группы "Интерфакс", предназначенная для комплексного решения задач в сфере управления репутацией и анализа эффективности PR. Решает задачи по мониторингу СМИ и соцсетей, анализу медиа-поля, проверке деловой репутации компаний и персон, позволяет пользователям оперативно реагировать на появление негатива в СМИ и соцмедиа, путём осуществления автоматизированного сбора и анализа публичной информации из более чем 60 тысяч источников.

Одной из функциональных возможностей SCAN является фактографический анализ новостной информации - выделение контекстов, в которых упоминается событие или действие некоторого субъекта на заданную тематику и с заданной тональностью.
На текущий момент SCAN умеет определять контексты более чем по 800 различным темам. Разработка каждой темы представляет собой длительный процесс по предварительному сбору и анализу большого корпуса текстовой информации для выделения характерных фраз, с последующим написанием машинных правил на специальном DSL (domain-specific language), в котором задействован целый отдел прикладных лингвистов.

Мы предлагаем вам принять участие в решении значимой для проекта SCAN задачи, которая позволяет расширить спектр выделяемых системой контекстов и снизит нагрузку на лингвистов:

Разработка средства автоматизированного поиска контекстов на заданные тематики. Нам важна семантическая близость к уже проработанным нами контекстам, чтобы не требовалось описывать каждый контекст в рамках одной тематики машинными правилами на специальном DSL:

- В качестве исходных данных выступают наборы размеченных корпусов на различные тематики.
- В качестве искомого контекста может выступать как часть предложения исходного текста, так и целое предложение, или даже набор предложений на ту же тему.